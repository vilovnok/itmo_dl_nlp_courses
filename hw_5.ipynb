{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61f6d8fa-4fb5-43f7-8b52-7cb66d23023e",
   "metadata": {},
   "source": [
    "### Домашнее задание 5 - 10 баллов\n",
    "\n",
    "В этом задании вам предстоит дообучить трансформерную модель для задачи классификации с помощью различных техник и сравнить их между собой.\n",
    "\n",
    "Датасет: [dair-ai/emotion](https://huggingface.co/datasets/dair-ai/emotion) \n",
    "\n",
    "Модель: [google-bert/bert-base-uncased](https://huggingface.co/google-bert/bert-base-uncased) (если хочется, можно заменить на что-то более интересное)\n",
    "\n",
    "1. Скачайте датасет и модель. Измерьте базовые метрики классификации перед началом экспериментов.\n",
    "\n",
    "**NB!** Для всех типов дообучения замерьте :\n",
    "- качество классификации на выходе\n",
    "- время дообучения\n",
    "- количество параметров для обучения\n",
    "- потребление ресурсов (не нужно заморачиваться с профайлингом - можно просто посмотреть в `nvidia-smi` или `torch.cuda.memory_allocated`)\n",
    "\n",
    "2. Обучите модель в режиме full finetuning - **1 балл**\n",
    "3. Обучите модель в режиме linear probing - реализуйте кастомную классификационную голову и обучайте только ее. Не забудьте описать, чем обусловлено устройство головы, как вы пришли к такой архитектуре - **2 балла**\n",
    "4. Обучите модель в режиме PEFT с использованием [prompt tuning или prefix tuning](https://ericwiener.github.io/ai-notes/AI-Notes/Large-Language-Models/Prompt-Tuning-and-Prefix-Tuning). При выборе метода напишите пару слов, почему решили остановиться именно на этом методе - **2 балла**\n",
    "4. Обучите модель в режиме PEFT с использованием LoRA. Попробуйте подобрать оптимальный ранг - `r`, при желании поэкспериментируйте с остальными гиперпараметрами. Опишите, чем обусловлена ваша финальная конфигурация - **2 балла**\n",
    "\n",
    "5. Соберите все результаты отдельных замеров в таблицу и сделайте выводы о вычислительной сложности методов, итоговом качестве и прочих наблюдаемых свойствах моделей - **1 балл**\n",
    "\n",
    "**Общее**\n",
    "\n",
    "- Принимаемые решения обоснованы (почему выбрана определенная архитектура/гиперпараметр/оптимизатор/преобразование и т.п.) - **1 балл**\n",
    "- Обеспечена воспроизводимость решения: зафиксированы random_state, ноутбук воспроизводится от начала до конца без ошибок - **1 балл**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0f7a69c-973d-4d5a-a92c-8e01511bb361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "import tabulate\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b620994d-ab4e-413e-ba80-d18071e30623",
   "metadata": {},
   "source": [
    "### 1. Загрузим датасет и модель. Измерим базовые метрики классификации перед началом экспериментов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e5fac44-f378-4a51-9d2f-a14f65ec404a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 22\n",
    "\n",
    "def seed_all(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        torch.backends.cudnn.deterministic = False\n",
    "\n",
    "\n",
    "seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6fb990d-0b3f-40cb-89b3-49cb44c5366f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"google-bert/bert-base-uncased\"\n",
    "dataset_id = \"dair-ai/emotion\"\n",
    "\n",
    "dataset = load_dataset(dataset_id)\n",
    "labels = dataset[\"train\"].features[\"label\"].names\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0e276a9-7ab9-4b5e-8eb5-93769fe09f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 16000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 2000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 2000\n",
      "    })\n",
      "})\n",
      "All classes: ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "print(dataset)\n",
    "print(f\"All classes: {labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a85157a8-2542-43ec-95f5-3006d9202f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c459a9eeb8d0491e816cb2927a8e3474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import TrainerCallback\n",
    "\n",
    "def tokenize_data(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "\n",
    "# Токенизируем данные\n",
    "tokenized_dataset = dataset.map(tokenize_data, batched=True)\n",
    "tokenized_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e23c538-a33e-48be-8f02-3e03b84effb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, true_labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "            gpu_mem_mb = torch.cuda.memory_allocated() / 1e6\n",
    "    else:\n",
    "        gpu_mem_mb = 0.0\n",
    "    \n",
    "    process = psutil.Process()\n",
    "    cpu_mem_mb = process.memory_info().rss / 1e6\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(true_labels, predictions),\n",
    "        **classification_report(\n",
    "            true_labels, \n",
    "            predictions,\n",
    "            target_names=labels,\n",
    "            output_dict=True,\n",
    "            zero_division=0\n",
    "        )[\"macro avg\"],\n",
    "        \"gpu_mem_mb\": gpu_mem_mb,\n",
    "        \"cpu_mem_mb\": cpu_mem_mb\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd5713e4-1f86-4f4d-806f-e896213bb1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 109,486,854\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_id,\n",
    "    num_labels=len(labels)\n",
    ")\n",
    "\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=1000,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    logging_steps=200,\n",
    "    weight_decay=0.01,\n",
    "    metric_for_best_model=\"f1-score\",\n",
    "    logging_dir=\"./logs\",\n",
    "    report_to=\"none\",\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e49ebc6-7bdc-4a30-8e33-9ae930f669d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:53]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+------------+\n",
      "| Метрика                 |   Значение |\n",
      "+=========================+============+\n",
      "| eval_loss               |     1.8489 |\n",
      "+-------------------------+------------+\n",
      "| eval_accuracy           |     0.1360 |\n",
      "+-------------------------+------------+\n",
      "| eval_precision          |     0.0404 |\n",
      "+-------------------------+------------+\n",
      "| eval_recall             |     0.1839 |\n",
      "+-------------------------+------------+\n",
      "| eval_f1-score           |     0.0653 |\n",
      "+-------------------------+------------+\n",
      "| eval_support            |  2000.0000 |\n",
      "+-------------------------+------------+\n",
      "| eval_gpu_mem_mb         |   887.1629 |\n",
      "+-------------------------+------------+\n",
      "| eval_cpu_mem_mb         |  2618.8186 |\n",
      "+-------------------------+------------+\n",
      "| eval_runtime            |     1.5341 |\n",
      "+-------------------------+------------+\n",
      "| eval_samples_per_second |  1303.6770 |\n",
      "+-------------------------+------------+\n",
      "| eval_steps_per_second   |    13.6890 |\n",
      "+-------------------------+------------+\n"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate(tokenized_dataset[\"test\"])\n",
    "print(tabulate.tabulate(\n",
    "    results.items(),\n",
    "    headers=[\"Метрика\", \"Значение\"],\n",
    "    tablefmt=\"grid\",\n",
    "    floatfmt=\".4f\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f054ff58-2a31-4bb3-ad49-355f2710b6b0",
   "metadata": {},
   "source": [
    "### 2. Обучим модель в режиме full finetuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9383c2e0-e0db-4fd2-bf99-12fb040f62e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='501' max='501' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [501/501 01:29, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Support</th>\n",
       "      <th>Gpu Mem Mb</th>\n",
       "      <th>Cpu Mem Mb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.833400</td>\n",
       "      <td>0.291104</td>\n",
       "      <td>0.910500</td>\n",
       "      <td>0.887907</td>\n",
       "      <td>0.877285</td>\n",
       "      <td>0.881769</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1775.213056</td>\n",
       "      <td>2884.747264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.211100</td>\n",
       "      <td>0.196382</td>\n",
       "      <td>0.929000</td>\n",
       "      <td>0.908102</td>\n",
       "      <td>0.905313</td>\n",
       "      <td>0.906375</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1775.213056</td>\n",
       "      <td>2884.890624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+------------+\n",
      "| Метрика                 |   Значение |\n",
      "+=========================+============+\n",
      "| eval_loss               |     0.1833 |\n",
      "+-------------------------+------------+\n",
      "| eval_accuracy           |     0.9260 |\n",
      "+-------------------------+------------+\n",
      "| eval_precision          |     0.8865 |\n",
      "+-------------------------+------------+\n",
      "| eval_recall             |     0.8834 |\n",
      "+-------------------------+------------+\n",
      "| eval_f1-score           |     0.8845 |\n",
      "+-------------------------+------------+\n",
      "| eval_support            |  2000.0000 |\n",
      "+-------------------------+------------+\n",
      "| eval_gpu_mem_mb         |  1775.0139 |\n",
      "+-------------------------+------------+\n",
      "| eval_cpu_mem_mb         |  3147.3500 |\n",
      "+-------------------------+------------+\n",
      "| eval_runtime            |     1.3571 |\n",
      "+-------------------------+------------+\n",
      "| eval_samples_per_second |  1473.6900 |\n",
      "+-------------------------+------------+\n",
      "| eval_steps_per_second   |    15.4740 |\n",
      "+-------------------------+------------+\n",
      "| epoch                   |     3.0000 |\n",
      "+-------------------------+------------+\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "\n",
    "results = trainer.evaluate(tokenized_dataset[\"test\"])\n",
    "print(tabulate.tabulate(\n",
    "    results.items(),\n",
    "    headers=[\"Метрика\", \"Значение\"],\n",
    "    tablefmt=\"grid\",\n",
    "    floatfmt=\".4f\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c95c37d-d614-4264-8efd-9e0f57067559",
   "metadata": {},
   "source": [
    "### 3. Обучим модель в режиме linear probing\n",
    "В качестве головы был выбран дополнительный слой трансформера, поскольку данное предложение усилит контекстное представления\n",
    "обеспечивая глубокую обработку скрытых состояний без дообучения всей модели. Думаю, дополнительное внимание лучше сработает, чем простой Linear(ReLU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b0e9833-f743-4d3e-88b7-0de454b18ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 7,683,078\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertConfig, BertTokenizer\n",
    "\n",
    "\n",
    "class TransformerClassifierHead(nn.Module):\n",
    "    def __init__(self, hidden_size, num_labels=6, num_layers=1, dropout=0.1):\n",
    "        super(TransformerClassifierHead, self).__init__()\n",
    "        \n",
    "        self.config = BertConfig(\n",
    "            hidden_size=hidden_size,\n",
    "            num_attention_heads=12,\n",
    "            intermediate_size=3072,\n",
    "            num_hidden_layers=num_layers,\n",
    "            hidden_dropout_prob=dropout\n",
    "        )\n",
    "\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            encoder_layer = nn.TransformerEncoderLayer(\n",
    "                d_model=hidden_size,\n",
    "                nhead=self.config.num_attention_heads,\n",
    "                dim_feedforward=self.config.intermediate_size,\n",
    "                dropout=dropout,\n",
    "                activation=\"gelu\",\n",
    "                batch_first=True\n",
    "            ),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "\n",
    "        self.pooler = nn.Linear(hidden_size, hidden_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.classifier = nn.Linear(hidden_size, num_labels)\n",
    "\n",
    "    \n",
    "    def forward(self, hidden_states):\n",
    "        if hidden_states.dim() == 2:\n",
    "            hidden_states = hidden_states.unsqueeze(1)  # [batch, 1, hidden]\n",
    "        \n",
    "        transformer_out = self.transformer(hidden_states)  # [batch, 1, hidden]\n",
    "        \n",
    "        pooled = self.tanh(self.pooler(transformer_out.squeeze(1)))  # [batch, hidden]\n",
    "        pooled = self.dropout(pooled)\n",
    "        \n",
    "        return self.classifier(pooled)\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_id,\n",
    "    num_labels=len(labels)\n",
    ")\n",
    "\n",
    "\n",
    "hidden_size = model.config.hidden_size # 768\n",
    "\n",
    "# Замораживаем слои\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Заменяем классификатор\n",
    "model.classifier = TransformerClassifierHead(hidden_size, len(labels))\n",
    "\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4aae5fd6-ad17-47d9-9714-0313edd89c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучается: classifier.transformer.layers.0.self_attn.in_proj_weight\n",
      "Обучается: classifier.transformer.layers.0.self_attn.in_proj_bias\n",
      "Обучается: classifier.transformer.layers.0.self_attn.out_proj.weight\n",
      "Обучается: classifier.transformer.layers.0.self_attn.out_proj.bias\n",
      "Обучается: classifier.transformer.layers.0.linear1.weight\n",
      "Обучается: classifier.transformer.layers.0.linear1.bias\n",
      "Обучается: classifier.transformer.layers.0.linear2.weight\n",
      "Обучается: classifier.transformer.layers.0.linear2.bias\n",
      "Обучается: classifier.transformer.layers.0.norm1.weight\n",
      "Обучается: classifier.transformer.layers.0.norm1.bias\n",
      "Обучается: classifier.transformer.layers.0.norm2.weight\n",
      "Обучается: classifier.transformer.layers.0.norm2.bias\n",
      "Обучается: classifier.pooler.weight\n",
      "Обучается: classifier.pooler.bias\n",
      "Обучается: classifier.classifier.weight\n",
      "Обучается: classifier.classifier.bias\n"
     ]
    }
   ],
   "source": [
    "# Все обучаемые параметры\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Обучается: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "141deae6-e1c0-4ab6-801b-ec1a0e449a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1670' max='1670' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1670/1670 03:51, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Support</th>\n",
       "      <th>Gpu Mem Mb</th>\n",
       "      <th>Cpu Mem Mb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.433300</td>\n",
       "      <td>1.315592</td>\n",
       "      <td>0.496500</td>\n",
       "      <td>0.427630</td>\n",
       "      <td>0.284316</td>\n",
       "      <td>0.248327</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>989.931520</td>\n",
       "      <td>3161.006080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+------------+\n",
      "| Метрика                 |   Значение |\n",
      "+=========================+============+\n",
      "| eval_loss               |     1.2817 |\n",
      "+-------------------------+------------+\n",
      "| eval_accuracy           |     0.5010 |\n",
      "+-------------------------+------------+\n",
      "| eval_precision          |     0.4325 |\n",
      "+-------------------------+------------+\n",
      "| eval_recall             |     0.2838 |\n",
      "+-------------------------+------------+\n",
      "| eval_f1-score           |     0.2553 |\n",
      "+-------------------------+------------+\n",
      "| eval_support            |  2000.0000 |\n",
      "+-------------------------+------------+\n",
      "| eval_gpu_mem_mb         |   989.7324 |\n",
      "+-------------------------+------------+\n",
      "| eval_cpu_mem_mb         |  3166.9453 |\n",
      "+-------------------------+------------+\n",
      "| eval_runtime            |     1.5989 |\n",
      "+-------------------------+------------+\n",
      "| eval_samples_per_second |  1250.8730 |\n",
      "+-------------------------+------------+\n",
      "| eval_steps_per_second   |    13.1340 |\n",
      "+-------------------------+------------+\n",
      "| epoch                   |    10.0000 |\n",
      "+-------------------------+------------+\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=1000,\n",
    "    learning_rate=1e-4,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=10,\n",
    "    logging_steps=1000,\n",
    "    weight_decay=0.01,\n",
    "    metric_for_best_model=\"f1-score\",\n",
    "    logging_dir=\"./logs\",\n",
    "    report_to=\"none\",\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=2,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "results = trainer.evaluate(tokenized_dataset[\"test\"])\n",
    "print(tabulate.tabulate(\n",
    "    results.items(),\n",
    "    headers=[\"Метрика\", \"Значение\"],\n",
    "    tablefmt=\"grid\",\n",
    "    floatfmt=\".4f\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2905fc0f-7802-4d80-bfc2-8b92683ebae7",
   "metadata": {},
   "source": [
    "### Обучите модель в режиме PEFT (Prompt tuning)\n",
    "Выбор параметров для Prompt Tuning обусловлено самой задачей текстовой классификации:\n",
    "\n",
    "- num_virtual_tokens=40 — достаточно длина промпта для того, чтобы уловить суть задачи.\n",
    "- token_dim=768 — соответствует размеру эмбеддингов модели BERT-base.\n",
    "- prompt_tuning_init=\"TEXT\" с prompt_tuning_init_text=\"Classify the emotion...\" — использование семантически осмысленной инициализации направляет модель с самого начала в сторону нужной задачи, ускоряя обучение.\n",
    "- base_model_name_or_path и tokenizer_name_or_path — использование предварительно обученной модели BERT-base-uncased даёт сильную основу, адаптированную под задачи NLP.\n",
    "\n",
    "В совокупности, эти параметры обеспечат баланс между управляемостью обучения и гибкостью (через виртуальные токены), снижая вероятность плохой начальной инициализации и повышая интерпретируемость подхода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ecfeb9b6-fed0-41c2-9233-24b5fc91d07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 30,720 || all params: 109,517,574 || trainable%: 0.0281\n"
     ]
    }
   ],
   "source": [
    "from peft import (\n",
    "    PromptTuningConfig,\n",
    "    get_peft_model,\n",
    "    TaskType\n",
    ")\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "peft_config = PromptTuningConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    num_virtual_tokens=40,  \n",
    "    token_dim=768,          \n",
    "    prompt_tuning_init=\"TEXT\",\n",
    "    prompt_tuning_init_text=\"Classify the emotion expressed in the following sentence:\",\n",
    "    base_model_name_or_path=\"bert-base-uncased\",\n",
    "    tokenizer_name_or_path=\"bert-base-uncased\"\n",
    ")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_id,\n",
    "    num_labels=len(labels),\n",
    "    return_dict=True\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e23b6f7-9038-4a4e-8427-77eaca44749e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33milike528149\u001b[0m (\u001b[33mr1char9\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/tank/scratch/rgurtsiev/workflow/itmo_dl_nlp_courses/wandb/run-20250509_161705-h6pd69qa</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/r1char9/huggingface/runs/h6pd69qa' target=\"_blank\">./peft_results</a></strong> to <a href='https://wandb.ai/r1char9/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/r1char9/huggingface' target=\"_blank\">https://wandb.ai/r1char9/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/r1char9/huggingface/runs/h6pd69qa' target=\"_blank\">https://wandb.ai/r1char9/huggingface/runs/h6pd69qa</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='420' max='420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [420/420 01:28, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.789000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.750400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.726700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.711300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+------------+\n",
      "| Метрика                 |   Значение |\n",
      "+=========================+============+\n",
      "| eval_loss               |     1.6830 |\n",
      "+-------------------------+------------+\n",
      "| eval_accuracy           |     0.3475 |\n",
      "+-------------------------+------------+\n",
      "| eval_precision          |     0.0580 |\n",
      "+-------------------------+------------+\n",
      "| eval_recall             |     0.1667 |\n",
      "+-------------------------+------------+\n",
      "| eval_f1-score           |     0.0860 |\n",
      "+-------------------------+------------+\n",
      "| eval_support            |  2000.0000 |\n",
      "+-------------------------+------------+\n",
      "| eval_gpu_mem_mb         |   896.8817 |\n",
      "+-------------------------+------------+\n",
      "| eval_cpu_mem_mb         |  3208.1797 |\n",
      "+-------------------------+------------+\n",
      "| eval_runtime            |     2.9741 |\n",
      "+-------------------------+------------+\n",
      "| eval_samples_per_second |   672.4620 |\n",
      "+-------------------------+------------+\n",
      "| eval_steps_per_second   |    14.1220 |\n",
      "+-------------------------+------------+\n",
      "| epoch                   |     5.0000 |\n",
      "+-------------------------+------------+\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./peft_results\",\n",
    "    learning_rate=1e-4,          \n",
    "    per_device_train_batch_size=32,\n",
    "    num_train_epochs=5,         \n",
    "    logging_steps=100,\n",
    "    save_strategy=\"no\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "results = trainer.evaluate(tokenized_dataset[\"test\"])\n",
    "print(tabulate.tabulate(\n",
    "    results.items(),\n",
    "    headers=[\"Метрика\", \"Значение\"],\n",
    "    tablefmt=\"grid\",\n",
    "    floatfmt=\".4f\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6736ae6-7ffe-4ab6-a507-95840675760f",
   "metadata": {},
   "source": [
    "### 4. Lora\n",
    "Выбор параметров LoRA обусловлен балансом между эффективностью, стабильностью обучения и вычислительными затратами:\n",
    "\n",
    "- r=8 (ранг) — оптимален для захвата основных паттернов данных без избыточной параметризации (слишком низкий r теряет информацию, высокий — увеличивает риск переобучения).\n",
    "- lora_alpha=16 — коэффициент масштабирования, согласованный с r (часто используют alpha = 2*r), чтобы сохранить соотношение влияния оригинальных и адаптивных весов.\n",
    "- lora_dropout=0.1 — умеренная регуляризация для улучшения обобщающей способности.\n",
    "- target_modules=[\"query\", \"value\"] — слои, связанные с механизмом внимания, наиболее критичны для адаптации модели к задаче.\n",
    "- bias=\"none\" — исключение смещений уменьшает число параметров и упрощает обучение.\n",
    "\n",
    "Параметры следуют рекомендациям оригинальной работы по LoRA и эмпирическим практикам для задач классификации (TaskType.SEQ_CLS), обеспечивая воспроизводимость и стабильность результатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d99d6284-7968-47be-9095-00ee01272c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 299,526 || all params: 109,786,380 || trainable%: 0.2728\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='420' max='420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [420/420 02:32, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Support</th>\n",
       "      <th>Gpu Mem Mb</th>\n",
       "      <th>Cpu Mem Mb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.091891</td>\n",
       "      <td>0.582500</td>\n",
       "      <td>0.282021</td>\n",
       "      <td>0.311175</td>\n",
       "      <td>0.242177</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>903.434240</td>\n",
       "      <td>3217.534976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.701087</td>\n",
       "      <td>0.739000</td>\n",
       "      <td>0.785870</td>\n",
       "      <td>0.569051</td>\n",
       "      <td>0.583188</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>903.434240</td>\n",
       "      <td>3217.756160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.086800</td>\n",
       "      <td>0.516600</td>\n",
       "      <td>0.803000</td>\n",
       "      <td>0.801747</td>\n",
       "      <td>0.703821</td>\n",
       "      <td>0.727249</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>903.434240</td>\n",
       "      <td>3217.743872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.086800</td>\n",
       "      <td>0.429801</td>\n",
       "      <td>0.852000</td>\n",
       "      <td>0.841210</td>\n",
       "      <td>0.785316</td>\n",
       "      <td>0.805047</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>903.434240</td>\n",
       "      <td>3218.006016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.529600</td>\n",
       "      <td>0.407840</td>\n",
       "      <td>0.857500</td>\n",
       "      <td>0.848730</td>\n",
       "      <td>0.792769</td>\n",
       "      <td>0.813186</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>903.434240</td>\n",
       "      <td>3218.399232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+------------+\n",
      "| Метрика                 |   Значение |\n",
      "+=========================+============+\n",
      "| eval_loss               |     0.3929 |\n",
      "+-------------------------+------------+\n",
      "| eval_accuracy           |     0.8640 |\n",
      "+-------------------------+------------+\n",
      "| eval_precision          |     0.8530 |\n",
      "+-------------------------+------------+\n",
      "| eval_recall             |     0.7706 |\n",
      "+-------------------------+------------+\n",
      "| eval_f1-score           |     0.7980 |\n",
      "+-------------------------+------------+\n",
      "| eval_support            |  2000.0000 |\n",
      "+-------------------------+------------+\n",
      "| eval_gpu_mem_mb         |   903.3011 |\n",
      "+-------------------------+------------+\n",
      "| eval_cpu_mem_mb         |  3218.3869 |\n",
      "+-------------------------+------------+\n",
      "| eval_runtime            |     5.4311 |\n",
      "+-------------------------+------------+\n",
      "| eval_samples_per_second |   368.2530 |\n",
      "+-------------------------+------------+\n",
      "| eval_steps_per_second   |     7.7330 |\n",
      "+-------------------------+------------+\n",
      "| epoch                   |     5.0000 |\n",
      "+-------------------------+------------+\n"
     ]
    }
   ],
   "source": [
    "from peft import (\n",
    "    LoraConfig, \n",
    "    TaskType, \n",
    "    get_peft_model\n",
    ")\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "        task_type=TaskType.SEQ_CLS,\n",
    "        inference_mode=False,\n",
    "        r=8,                # Ранг адаптеров\n",
    "        lora_alpha=16,      # Коэффициент масштабирования\n",
    "        lora_dropout=0.1,   # Дропаут для регуляризации\n",
    "        target_modules=[\"query\", \"value\"],  # Слои для применения LoRA\n",
    "        bias=\"none\"\n",
    "    )\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_id,\n",
    "    num_labels=len(labels)\n",
    ")\n",
    "\n",
    "lora_model = get_peft_model(model, lora_config)\n",
    "lora_model.print_trainable_parameters()\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"./lora_results\",\n",
    "    learning_rate=3e-4,\n",
    "    per_device_train_batch_size=32,\n",
    "    num_train_epochs=5,\n",
    "    eval_strategy=\"epoch\",\n",
    "    logging_steps=200\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=lora_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "results = trainer.evaluate(tokenized_dataset[\"test\"])\n",
    "print(tabulate.tabulate(\n",
    "    results.items(),\n",
    "    headers=[\"Метрика\", \"Значение\"],\n",
    "    tablefmt=\"grid\",\n",
    "    floatfmt=\".4f\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1c9610-fa7e-4c44-aa17-e651c908c7e8",
   "metadata": {},
   "source": [
    "# Подводим итоги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5064c0c7-6360-48e9-828e-cc97a077fe15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------+-----------------+------------------+---------------+-----------+----------------+----------------+---------------+-------------+---------+\n",
      "| Метод           |   eval_loss |   eval_accuracy |   eval_precision |   eval_recall |   eval_f1 |   eval_support |   eval_runtime |   samples/sec |   steps/sec |   epoch |\n",
      "+=================+=============+=================+==================+===============+===========+================+================+===============+=============+=========+\n",
      "| Full Finetuning |      0.1862 |          0.9255 |           0.8858 |        0.8784 |    0.8811 |      2000.0000 |         2.3639 |      846.0490 |      8.8840 |  3.0000 |\n",
      "+-----------------+-------------+-----------------+------------------+---------------+-----------+----------------+----------------+---------------+-------------+---------+\n",
      "| Linear Probing  |      1.2817 |          0.5010 |           0.4325 |        0.2838 |    0.2553 |      2000.0000 |         2.4988 |      800.3830 |      8.4040 | 10.0000 |\n",
      "+-----------------+-------------+-----------------+------------------+---------------+-----------+----------------+----------------+---------------+-------------+---------+\n",
      "| Prompt Tuning   |      1.6830 |          0.3475 |           0.0580 |        0.1667 |    0.0860 |      2000.0000 |         4.8374 |      413.4450 |      8.6820 |  5.0000 |\n",
      "+-----------------+-------------+-----------------+------------------+---------------+-----------+----------------+----------------+---------------+-------------+---------+\n",
      "| LoRA            |      0.4083 |          0.8535 |           0.8219 |        0.7636 |    0.7829 |      2000.0000 |         5.1118 |      391.2530 |      8.2160 |  5.0000 |\n",
      "+-----------------+-------------+-----------------+------------------+---------------+-----------+----------------+----------------+---------------+-------------+---------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "\n",
    "data = [\n",
    "    [\"Full Finetuning\", 0.1862, 0.9255, 0.8858, 0.8784, 0.8811, 2000.0, 2.3639, 846.0490, 8.8840, 3.0],\n",
    "    [\"Linear Probing\", 1.2817, 0.5010, 0.4325, 0.2838, 0.2553, 2000.0, 2.4988, 800.3830, 8.4040, 10.0],\n",
    "    [\"Prompt Tuning\", 1.6830, 0.3475, 0.0580, 0.1667, 0.0860, 2000.0, 4.8374, 413.4450, 8.6820, 5.0],\n",
    "    [\"LoRA\", 0.4083, 0.8535, 0.8219, 0.7636, 0.7829, 2000.0, 5.1118, 391.2530, 8.2160, 5.0]\n",
    "]\n",
    "\n",
    "headers = [\n",
    "    \"Метод\", \"eval_loss\", \"eval_accuracy\", \"eval_precision\", \n",
    "    \"eval_recall\", \"eval_f1\", \"eval_support\", \"eval_runtime\", \n",
    "    \"samples/sec\", \"steps/sec\", \"epoch\"\n",
    "]\n",
    "\n",
    "print(tabulate(data, headers=headers, tablefmt=\"grid\", floatfmt=\".4f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c6c08a-099d-4c20-ba6a-28330f7e39dd",
   "metadata": {},
   "source": [
    "Full Finetuning и LoRA демонстрируют высокие показатели (F1-score ~0.88), что говорит об их эффективности.   \n",
    "\n",
    "Правда LoRA уступает Full Finetuning, что делает его менее предпочительным выбором для данной задач (F1-score ~0.78).\n",
    "\n",
    "Prompt Tuning (F1-score ~0.0860 ) и Linear Probing (F1-score ~0.26) значительно уступают в качестве.\n",
    "\n",
    "\n",
    "На этих экспериментах наглядно видно, что дополнительное внимание всяко лучше, чем без него!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
